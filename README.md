# PCA for Iris Dataset

In this project, we explore Principal Component Analysis (PCA) as a technique for identifying low-dimensional structure in data and finding good representations of the data in that subspace. Specifically, we apply PCA on the Iris dataset using scikit-learn library.

## Dataset

We load the Iris dataset using scikit-learn's built-in load_iris() function. The dataset consists of 150 instances, each with four features: sepal length, sepal width, petal length, and petal width. The target variable is the iris species, which has three possible values: setosa, versicolor, and virginica.

from sklearn.datasets import load_iris
iris = load_iris()
X = iris.data
y = iris.target

### Part (a): PCA on the raw dataset

We perform PCA on the entire raw dataset for k = 1, 2, 3, 4 components. We calculate the amount of variance explained by the first principal component and observe how the fraction of variation explained in data varies as k changes.

### Part (b): PCA on preprocessed data

We apply preprocessing operations on the raw dataset and repeat Part (a) on the processed data. We explain any differences observed compared to Part (a) and justify the results.

### Part (c): Projection on 2D subspace

We project the raw four-dimensional data down to a two-dimensional subspace generated by the first two top principal components from Part (b). We produce a scatter plot of the data and ensure to plot each of the three classes differently using color or different markers. We observe the three Iris flower clusters.

### Part (d): K-Means Clustering

We cluster the data from Part (c) into three clusters using K-Means clustering algorithm either by implementing our own k-means++ algorithm from previous homework or using scikit-learn's KMeans class. We explain the observations made during clustering.

## Conclusion

This project demonstrates the application of PCA on the Iris dataset to identify low-dimensional structure and find good representations of the data in that subspace. We also apply preprocessing operations and observe the differences in results. Finally, we project the data onto a two-dimensional subspace and perform clustering to observe the cluster formations.

## Academic Integrity Statement

Please note that all work included in this project is the original work of the author, and any external sources or references have been properly cited and credited. It is strictly prohibited to copy, reproduce, or use any part of this work without permission from the author.

If you choose to use any part of this work as a reference or resource, you are responsible for ensuring that you do not plagiarize or violate any academic integrity policies or guidelines. The author of this work cannot be held liable for any legal or academic consequences resulting from the misuse or misappropriation of this work.

In summary, any unauthorized copying or use of this work may result in serious consequences, including but not limited to academic penalties, legal action, and damage to personal and professional reputation. Therefore, please use this work only as a reference and always ensure that you properly cite and attribute any sources or references used.
